# Evaluation of stereotypical biases in recent GPT models 
### Master Thesis - M.Sc. Business Intelligence and Process Management 
### HWR Berlin

#### Abstract
Large language models, and particularly GPT models, are increasingly being used in a variety of different domains by individual users as well as companies.  However, previous research has discovered biases in these models that are harmful to society. This study assesses GPT-3.5 Turbo and GPT-4 stereotypical biases in the categories of age, disability status, gender identity, nationality, physical appearance, race/ethnicity, religion, socio-economic status, and sexual orientation, utilizing the BBQ and CrowS-Pairs datasets. The models are presented with a stereotype and an anti-stereotype option and asked to select the most accurate one.  Additionally, it explores inducing a biased response with an adversarial attack by replacing the words that contributed the most to the modelâ€™s response in the original sentence with synonyms.  Results show that both models are biased toward stereotypes. GPT-4 is better than GPT-3.5 Turbo at refusing to follow the instructions to avoid generating biased content. However, for the cases in which the model gave a response, its higher capability is also associated with a higher level of bias. Finally, the designed adversarial attack did not prove to be an effective strategy to significantly and consistently increase the bias of the models.   Overall, this study evidences the need for continued research and refinement of GPT models to make them more aligned with societal values. 

#### Repository details

The original datasets are in [benchmarks](benchmarks) folder, including a [quality assesment of CrowS-Pairs](benchmarks\CrowS-Pairs\crows_pairs_quality_check.ipynb). The EDA and pre-processing is in [EDA_Preprocessing.ipynb](EDA_Preprocessing.ipynb).
The completions for the RQ1 are performed in [RQ1completions.ipynb](RQ1completions.ipynb) and stored in [data\RQ1](data\RQ1). The analysis of the responses is in [results_analysis\RQ1](results_analysis\RQ1), including the [undetermined responses labeling](results_analysis\RQ1\label_undetermined_responses).
After the analysis of RQ1, as as part of the adversarial attack of RQ2, the models are asked the words that contributed the most to their response in [get_important_words.ipynb](get_important_words.ipynb) and they are stored in [data\RQ2\important_words](data\RQ2\important_words).
With the important words, the adversarial examples are constructed in [adversarial_examples.ipynb](adversarial_examples.ipynb) and stored in [data\RQ2\adv_sentences](data\RQ2\adv_sentences).
Finally, a new round of completions is conducted with the adversarial examples in [RQ2completions.ipynb](RQ2completions.ipynb). The responses are stored in [data\RQ2\adv_completions](data\RQ2\adv_completions) and analysed in [results_analysis\RQ2](results_analysis\RQ2).
